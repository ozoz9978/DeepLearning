{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ae1bda-2503-44e4-8aa3-286242831695",
   "metadata": {},
   "source": [
    "# TENSORFLOW 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c03f4ec-ef20-4860-8d33-7d56423ea60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.1-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached h5py-3.11.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached grpcio-1.63.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached optree-0.11.0-cp311-cp311-win_amd64.whl.metadata (46 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.16.1-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl (377.0 MB)\n",
      "   ---------------------------------------- 0.0/377.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/377.0 MB 1.3 MB/s eta 0:04:55\n",
      "   ---------------------------------------- 0.1/377.0 MB 1.4 MB/s eta 0:04:21\n",
      "   ---------------------------------------- 2.7/377.0 MB 19.4 MB/s eta 0:00:20\n",
      "    --------------------------------------- 7.6/377.0 MB 40.4 MB/s eta 0:00:10\n",
      "   - ------------------------------------- 12.5/377.0 MB 108.8 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 17.5/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 22.4/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------ 26.8/377.0 MB 110.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 32.1/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   --- ----------------------------------- 37.5/377.0 MB 108.8 MB/s eta 0:00:04\n",
      "   ---- ---------------------------------- 42.4/377.0 MB 108.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 47.2/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   ----- --------------------------------- 52.6/377.0 MB 110.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 56.5/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 61.2/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 65.2/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   ------- ------------------------------- 70.2/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ------- ------------------------------- 75.4/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------ 80.7/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------ 85.8/377.0 MB 131.2 MB/s eta 0:00:03\n",
      "   --------- ----------------------------- 90.6/377.0 MB 110.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 95.8/377.0 MB 93.9 MB/s eta 0:00:03\n",
      "   ---------- ---------------------------- 99.7/377.0 MB 110.0 MB/s eta 0:00:03\n",
      "   ---------- --------------------------- 104.9/377.0 MB 110.0 MB/s eta 0:00:03\n",
      "   ----------- --------------------------- 108.6/377.0 MB 93.9 MB/s eta 0:00:03\n",
      "   ----------- --------------------------- 113.1/377.0 MB 93.9 MB/s eta 0:00:03\n",
      "   ----------- -------------------------- 118.3/377.0 MB 110.0 MB/s eta 0:00:03\n",
      "   ------------ -------------------------- 120.4/377.0 MB 93.9 MB/s eta 0:00:03\n",
      "   ------------ -------------------------- 123.7/377.0 MB 93.9 MB/s eta 0:00:03\n",
      "   ------------ -------------------------- 123.7/377.0 MB 93.9 MB/s eta 0:00:03\n",
      "   ------------ -------------------------- 124.0/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 129.3/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 131.1/377.0 MB 54.7 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 132.1/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 132.1/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 132.1/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 132.2/377.0 MB 26.2 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 135.8/377.0 MB 32.7 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 137.4/377.0 MB 32.7 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 137.4/377.0 MB 32.7 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 138.2/377.0 MB 23.4 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 142.6/377.0 MB 46.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 144.7/377.0 MB 43.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 144.7/377.0 MB 43.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 144.7/377.0 MB 43.5 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 146.8/377.0 MB 28.5 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 146.8/377.0 MB 28.5 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 147.1/377.0 MB 22.6 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 152.0/377.0 MB 29.7 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 155.2/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 158.3/377.0 MB 81.8 MB/s eta 0:00:03\n",
      "   ---------------- ---------------------- 159.0/377.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 162.5/377.0 MB 59.8 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 163.3/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 168.4/377.0 MB 54.4 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 172.0/377.0 MB 65.2 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 172.0/377.0 MB 65.2 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 174.0/377.0 MB 54.7 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 174.1/377.0 MB 54.7 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 174.1/377.0 MB 54.7 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 176.2/377.0 MB 32.8 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 176.2/377.0 MB 32.8 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 176.2/377.0 MB 32.8 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 176.5/377.0 MB 22.6 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 178.3/377.0 MB 22.6 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 179.3/377.0 MB 19.9 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 180.3/377.0 MB 20.5 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 180.3/377.0 MB 20.5 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 183.9/377.0 MB 19.8 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 188.6/377.0 MB 54.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 191.9/377.0 MB 93.0 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 191.9/377.0 MB 93.0 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 191.9/377.0 MB 93.0 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 191.9/377.0 MB 93.0 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 191.9/377.0 MB 93.0 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 191.9/377.0 MB 93.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 196.3/377.0 MB 29.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 201.4/377.0 MB 28.4 MB/s eta 0:00:07\n",
      "   -------------------- ----------------- 206.6/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 209.3/377.0 MB 81.8 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 214.1/377.0 MB 81.8 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 218.0/377.0 MB 93.9 MB/s eta 0:00:02\n",
      "   ---------------------- --------------- 222.9/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 226.0/377.0 MB 93.9 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 229.1/377.0 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 234.2/377.0 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 237.2/377.0 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 239.1/377.0 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 243.4/377.0 MB 65.2 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 244.1/377.0 MB 54.7 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 248.8/377.0 MB 73.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 251.5/377.0 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 252.8/377.0 MB 54.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 252.9/377.0 MB 43.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 253.0/377.0 MB 34.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 253.2/377.0 MB 32.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 253.8/377.0 MB 28.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 258.9/377.0 MB 31.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 263.2/377.0 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ---------- 268.5/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 273.4/377.0 MB 110.0 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 274.8/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 274.9/377.0 MB 72.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 274.9/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 275.0/377.0 MB 40.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 275.2/377.0 MB 32.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 275.4/377.0 MB 28.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 276.2/377.0 MB 25.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 280.5/377.0 MB 24.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 282.4/377.0 MB 22.5 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 284.1/377.0 MB 21.1 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 287.7/377.0 MB 54.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 289.9/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 292.5/377.0 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 294.1/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 295.7/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 295.7/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 295.7/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 295.7/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 295.7/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 297.1/377.0 MB 22.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 299.8/377.0 MB 23.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 303.3/377.0 MB 26.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 305.5/377.0 MB 26.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 307.2/377.0 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 307.2/377.0 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 307.2/377.0 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 307.2/377.0 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 308.3/377.0 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 308.3/377.0 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 308.3/377.0 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 308.3/377.0 MB 28.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 311.3/377.0 MB 19.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 314.1/377.0 MB 19.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 318.0/377.0 MB 32.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 322.5/377.0 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 325.7/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 330.6/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 335.2/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 341.3/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 344.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 344.1/377.0 MB 59.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 344.3/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 344.6/377.0 MB 36.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 346.2/377.0 MB 34.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 346.7/377.0 MB 29.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 348.2/377.0 MB 27.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 351.0/377.0 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 354.4/377.0 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 357.3/377.0 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 361.0/377.0 MB 65.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 365.1/377.0 MB 73.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  369.2/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.1/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 377.0/377.0 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Downloading grpcio-1.63.0-cp311-cp311-win_amd64.whl (3.9 MB)\n",
      "   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 2.3/3.9 MB 48.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.7/3.9 MB 28.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/3.9 MB 31.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.9/3.9 MB 24.9 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 2.4/3.0 MB 77.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 38.1 MB/s eta 0:00:00\n",
      "Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.6/1.1 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 17.5 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.1/26.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 3.6/26.4 MB 46.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 6.3/26.4 MB 57.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 8.5/26.4 MB 49.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.9/26.4 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.8/26.4 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 15.0/26.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.9/26.4 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.1/26.4 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.5/26.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.1/26.4 MB 28.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.2/26.4 MB 29.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.3/26.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.4/26.4 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.7/26.4 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 26.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.7/127.7 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 3.5/5.5 MB 75.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 70.3 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 46.1 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp311-cp311-win_amd64.whl (245 kB)\n",
      "   ---------------------------------------- 0.0/245.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 245.0/245.0 kB 14.7 MB/s eta 0:00:00\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.63.0 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: mecab-python 0.996-ko-0.9.2-msvc has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of mecab-python or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e755b-1bd4-4784-b27d-5a530b7b47e3",
   "metadata": {},
   "source": [
    "# 패키지 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c45f29-06f7-4eda-8d1a-26a95d837812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d736dc-1d61-4d1e-bf3c-80325daa0ec4",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5aca99-86a8-41c4-bb72-bd069e944486",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "BATCH = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b46eb-f7c8-4b98-813a-f124c6d3d4af",
   "metadata": {},
   "source": [
    "# 가상 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787dc369-cefb-4439-8fe9-ce069ac694f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9155c21e-2cbd-4ee0-9709-6e49fabe8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data = np.random.random((1000,100))\n",
    "label = np.random.randint(0,6,(1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6e53ac-4c7a-474e-98f1-f28ff1e643ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.549 0.715 0.603 0.545 0.424 0.646 0.438 0.892 0.964 0.383 0.792 0.529\n",
      " 0.568 0.926 0.071 0.087 0.02  0.833 0.778 0.87  0.979 0.799 0.461 0.781\n",
      " 0.118 0.64  0.143 0.945 0.522 0.415 0.265 0.774 0.456 0.568 0.019 0.618\n",
      " 0.612 0.617 0.944 0.682 0.36  0.437 0.698 0.06  0.667 0.671 0.21  0.129\n",
      " 0.315 0.364 0.57  0.439 0.988 0.102 0.209 0.161 0.653 0.253 0.466 0.244\n",
      " 0.159 0.11  0.656 0.138 0.197 0.369 0.821 0.097 0.838 0.096 0.976 0.469\n",
      " 0.977 0.605 0.739 0.039 0.283 0.12  0.296 0.119 0.318 0.414 0.064 0.692\n",
      " 0.567 0.265 0.523 0.094 0.576 0.929 0.319 0.667 0.132 0.716 0.289 0.183\n",
      " 0.587 0.02  0.829 0.005]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878a562-ff7d-4921-9cb2-e44f6ba0e3ee",
   "metadata": {},
   "source": [
    "# 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b15ee5c-1377-46e9-bc1d-98e2504e695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,232</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m3,232\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,265</span> (12.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,265\u001b[0m (12.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,265</span> (12.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,265\u001b[0m (12.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=32,activation='relu',input_dim=100))\n",
    "model.add(Dense(units=1,activation='softmax'))\n",
    "print(model.summary()) #params : 가중치 32x100개 + 편향 32개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca117b8-cfb8-40ff-890b-7a6488bbfc01",
   "metadata": {},
   "source": [
    "# 학습과정 모니터링 셋팅(Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbada212-35e0-4a60-8f1c-8974d7b54b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "log_dir = 'c:\\Logs\\\\'+datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "# 히스토그램 1 에폭마다 활성화 함수의 출력 히스토그램 기록\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440bbb9-f637-4d73-9d43-01dd0411e125",
   "metadata": {},
   "source": [
    "# 모델 컴파일 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39179627-a58a-4d7d-8a8a-326921e33876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1658 - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1649 - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1811 - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1886 - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1710 - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1514 - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1688 - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1704 - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1628 - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1686 - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1516 - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1674 - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1722 - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1612 - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1484 - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1626 - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1710 - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1562 - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1455 - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1598 - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1682 - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1486 - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1638 - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1651 - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1557 - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1672 - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1643 - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1707 - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1583 - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1652 - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1606 - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1425 - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1688 - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1501 - loss: 0.0000e+00 \n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1745 - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1592 - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1674 - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1836 - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1363 - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1495 - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1454 - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1545 - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1537 - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1632 - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1673 - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1695 - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1657 - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1623 - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1616 - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1496 - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1720 - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1736 - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1675 - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1796 - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1874 - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1681 - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1740 - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1547 - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1597 - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1723 - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1752 - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1697 - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1684 - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1819 - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1579 - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1618 - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1529 - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1497 - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1662 - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1590 - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1649 - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1483 - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1747 - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1382 - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1637 - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1564 - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1625 - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1747 - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1703 - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2003 - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1605 - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1765 - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1593 - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1663 - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1534 - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1761 - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1550 - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1623 - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1821 - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1656 - loss: 0.0000e+00 \n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1449 - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1631 - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1809 - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1763 - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1514 - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1641 - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1460 - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1733 - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1659 - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x230e2c0a610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(data, label, epochs=EPOCH, batch_size = BATCH, verbose=1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546db263-a10f-4b5c-af9d-2aef5aa2534f",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "193ac096-7420-4a9c-baad-d491a5f99799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1784 - loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730e2dc-09bb-4d50-b334-d1e983b8aca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
